{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 4 - Chapter 2\n",
    "In this chapter I have demonstrated **unstructured level 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unstructured Level 3**\n",
    "<br>\n",
    "Apply multiple representations and compare and contrast them for different end results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstructured Level 3\n",
    "For this portion of my portfolio, I will be briefly touching upon the different representations of unstructured data covered in **Assignment 12**. To refresh, here are the different methods we can use:\n",
    "\n",
    "**CountVectorizer**\n",
    "<br>\n",
    "Returns an encoded vector with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "\n",
    "**TfidfVectorizer**\n",
    "<br>\n",
    "Allows use to tokenize documents, learn similar vocabularies and the frequencies/weights of different works in documents (but not across documents), and allows you to encode new documents.\n",
    "\n",
    "**HashingVectorizer**\n",
    "<br>\n",
    "Uses a one-way hash of words to convert them into integers, and then tokenizes and encodes the documents as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this portfolio, I will be comparing and contrasting **CountVectorizer** with **TfidVectorizer**. Here are the **similarities and differences** between these two methods:\n",
    "* TfidVectorizer returns a float instead of an int like CountVectorizer.\n",
    "* In TfidfVectorizer we consider overall document weightage of a word. It helps us in dealing with most frequent words.\n",
    "* In CountVectorizer we only count the number of times a word appears in the document which results in biasing in favour of most frequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I will be completing Assignment 12 with both **CountVectorizer** and **TfidVectorizer**, and then comparing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from math import sqrt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "news = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping labels that are not necessary\n",
    "news.drop(labels=['id','title'], axis='columns', inplace=True)\n",
    "news.head()\n",
    "# Separate text from labels\n",
    "text = news['text']\n",
    "labels = news['label']\n",
    "# Vectorize Data\n",
    "counts = CountVectorizer(analyzer = \"word\")\n",
    "ng_vec = counts.fit_transform(text).toarray()\n",
    "# get_feature_names method will return them as a sorted list instead of a dictionary with numbers.\n",
    "counts_df = pd.DataFrame(ng_vec, columns=counts.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts_df, labels, test_size = 1000)\n",
    "\n",
    "# Naive Bayes Model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "# Scoring the model\n",
    "clf.score(X_test, y_test)\n",
    "# Making predictions on test data\n",
    "y_pred_test = clf.predict(X_test)\n",
    "# Making predictions on training data\n",
    "y_pred_train = clf.predict(X_train)\n",
    "# Training Accuracy\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "# Testing Accuracy\n",
    "test_acc = accuracy_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313964386129334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using TfidVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize Data\n",
    "tfid = TfidfVectorizer(analyzer = \"word\")\n",
    "tfid_vec = tfid.fit_transform(text).toarray()\n",
    "tfid_df = pd.DataFrame(tfid_vec, columns=tfid.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, split for TFID\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfid_df, labels, test_size = 1000)\n",
    "\n",
    "# Naive Bayes Model\n",
    "clf2 = MultinomialNB()\n",
    "clf2.fit(X_train, y_train)\n",
    "# Scoring the model\n",
    "clf2.score(X_test, y_test)\n",
    "# Making predictions on test data\n",
    "y_pred_test2 = clf2.predict(X_test)\n",
    "# Making predictions on training data\n",
    "y_pred_train2 = clf2.predict(X_train)\n",
    "# Training Accuracy\n",
    "train_acc2 = accuracy_score(y_train, y_pred_train2)\n",
    "# Testing Accuracy\n",
    "test_acc2 = accuracy_score(y_test, y_pred_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822867853795688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will summarize the results of these two vectorizers, and compare/contrast them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.931396</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.882287</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Test Accuracy\n",
       "0        0.931396          0.867\n",
       "1        0.882287          0.820"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling dataframe\n",
    "compare_results = pd.DataFrame({'Train Accuracy': [train_acc, train_acc2],\n",
    "                           'Test Accuracy': [test_acc, test_acc2]})\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the compiled dataframe (with 0 being CountVectorizer and 1 being TfidVectorizer), that the accuracies for both the training and testing sets are better with **CountVectorizer**. \n",
    "\n",
    "In the future, I would also like to optimize the hyperparamters of these vectorizers, but I don't have enough time. Maybe that will be a fun winter-break project :D"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
